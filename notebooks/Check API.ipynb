{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import sys\n",
    "from os.path import join\n",
    "import pickle\n",
    "sys.path.append('/home/rogupta/mannheim-nel/')\n",
    "from collections import defaultdict\n",
    "import tagme\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import spacy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_load(path):\n",
    "    assert os.path.exists(path)\n",
    "\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    return data\n",
    "\n",
    "def json_load(path):\n",
    "    assert os.path.exists(path)\n",
    "\n",
    "    with open(path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/work/rogupta/mannheim-nel-data/'\n",
    "datasets = ['conll-train', 'conll-dev', 'msnbc', 'ace2004']\n",
    "tagme.GCUBE_TOKEN = \"88c693df-a43f-4086-b3bc-0b555bfbc9bb-843339462\"\n",
    "PORT = \"127.0.0.1:5000\"\n",
    "DATASET = 'msnbc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd = json_load(join(data_path, 'dicts/redirects.json'))\n",
    "ent2id = json_load(join(data_path, 'dicts/redirects.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2c = {}\n",
    "id2c_conll = pickle_load(join(data_path, 'Conll', 'conll_raw_text.pickle'))\n",
    "id2c['conll-train'] = id2c_conll['train']\n",
    "id2c['conll-dev'] = id2c_conll['dev']\n",
    "examples = {}\n",
    "\n",
    "for d_name in datasets[2:]:\n",
    "    id2c[d_name], examples[d_name] = pickle_load(join(data_path, 'datasets', f'raw_{d_name}.pickle'))\n",
    "\n",
    "for d_name in datasets[:2]:\n",
    "    _, examples[d_name] = pickle_load(join(data_path, 'Conll', f\"conll-{d_name.split('-')[-1]}.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = {dataset : {} for dataset in datasets}\n",
    "for dataset, exs in examples.items():\n",
    "    for ex in exs:\n",
    "        c_id, (mention, ent_str, span, _) = ex\n",
    "        if c_id not in gold[dataset]:\n",
    "            gold[dataset][c_id] = {'mentions': [],\n",
    "                          'ents': [],\n",
    "                          'spans': []}\n",
    "        gold[dataset][c_id]['mentions'].append(mention)\n",
    "        gold[dataset][c_id]['ents'].append(ent_str)\n",
    "        gold[dataset][c_id]['spans'].append(span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "barack_text = \"\"\"Barack Hussein Obama II (/bəˈrɑːk huːˈseɪn oʊˈbɑːmə/ (About this sound listen);[1] born August 4, 1961) is an American politician who served as the 44th President of the United States from January 20, 2009, to January 20, 2017. A member of the Democratic Party, he was the first African American to be elected to the presidency and previously served as a United States Senator from Illinois (2005–2008).\n",
    "Obama was born in 1961 in Honolulu, Hawaii, two years after the territory was admitted to the Union as the 50th state. Raised largely in Hawaii, he also lived for a year of his childhood in the State of Washington and four years in Indonesia. After graduating from Columbia University in 1983, he worked as a community organizer in Chicago. In 1988, he enrolled in Harvard Law School, where he was the first black president of the Harvard Law Review. After graduating, he became a civil rights attorney and a professor, teaching constitutional law at the University of Chicago Law School from 1992 to 2004. He represented the 13th district for three terms in the Illinois Senate from 1997 to 2004, when he ran for the U.S. Senate. He received national attention in 2004 with his March primary win, his well-received July Democratic National Convention keynote address, and his landslide November election to the Senate. In 2008, he was nominated for president a year after his campaign began and after a close primary campaign against Hillary Clinton. He was elected over Republican John McCain and was inaugurated on January 20, 2009. Nine months later, he was named the 2009 Nobel Peace Prize laureate, accepting the award with the caveat that he felt there were others \"far more deserving of this honor than I\".\n",
    "During his first two years in office, Obama signed many landmark bills into law. The main reforms were the Patient Protection and Affordable Care Act (often referred to as \"Obamacare\", shortened as the \"Affordable Care Act\"), the Dodd–Frank Wall Street Reform and Consumer Protection Act, and the Don't Ask, Don't Tell Repeal Act of 2010. The American Recovery and Reinvestment Act of 2009 and Tax Relief, Unemployment Insurance Reauthorization, and Job Creation Act of 2010 served as economic stimulus amidst the Great Recession. After a lengthy debate over the national debt limit, he signed the Budget Control and the American Taxpayer Relief Acts. In foreign policy, he increased U.S. troop levels in Afghanistan, reduced nuclear weapons with the United States–Russia New START treaty, and ended military involvement in the Iraq War. He ordered military involvement in Libya in opposition to Muammar Gaddafi; Gaddafi was killed by NATO-assisted forces, and he also ordered the military operation that resulted in the deaths of Osama bin Laden and suspected Yemeni Al-Qaeda operative Anwar al-Awlaki.\n",
    "\"\"\"\n",
    "barack_mentions = ['President', 'United States', 'African American', 'Democratic Party']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_full(text, max_cands=100):\n",
    "    data_json = json.dumps({'text': text,\n",
    "                            'max_cands': max_cands})\n",
    "    response_json = requests.post(f\"http://{PORT}/link\", data=data_json).json()\n",
    "    ents = response_json['entities']\n",
    "    mentions = response_json['mentions']\n",
    "    spans = response_json['spans']\n",
    "    \n",
    "    return ents, mentions, spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_mention(text, user_mentions, user_spans, max_cands=100):\n",
    "    data_json = json.dumps({'text': text,\n",
    "                            'mentions': user_mentions,\n",
    "                            'spans': user_spans,\n",
    "                            'max_cands': max_cands})\n",
    "    response_json = requests.post(f\"http://{PORT}/link\", data=data_json).json()\n",
    "    ents = response_json['entities']\n",
    "    mentions = response_json['mentions']\n",
    "    \n",
    "    return ents, mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_results(num_text, dataset='dev', max_cands=100):\n",
    "    results = {}\n",
    "    times = []\n",
    "    for doc_id, text in list(id2c[dataset].items())[:num_text]:\n",
    "        results[doc_id] = {}\n",
    "\n",
    "        tic = datetime.now()\n",
    "        ents, mentions, spans = get_response_full(text)\n",
    "        toc = datetime.now()\n",
    "        times.append({'len': len(text), 'time (s)': (toc - tic).total_seconds()})\n",
    "        results[doc_id]['mentions'] = mentions\n",
    "        results[doc_id]['ents'] = ents\n",
    "        results[doc_id]['spans'] = [tuple(span) for span in spans]\n",
    "    \n",
    "    return results, times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mention_results(num_text, dataset='conll-dev', max_cands=100):\n",
    "    results = {}\n",
    "    times = []\n",
    "    for doc_id, text in list(id2c[dataset].items())[:num_text]:\n",
    "        if doc_id not in gold[dataset]:\n",
    "            continue\n",
    "        results[doc_id] = {}\n",
    "        user_mentions = gold[dataset][doc_id]['mentions']\n",
    "        user_spans = gold[dataset][doc_id]['spans']\n",
    "        try:\n",
    "            ents, mentions = get_response_mention(text, user_mentions, user_spans, max_cands=100)\n",
    "        except Exception as e:\n",
    "            print(Text, user_mentions)\n",
    "        results[doc_id]['mentions'] = mentions\n",
    "        results[doc_id]['ents'] = ents\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_idx(pred_spans, gold_spans, thresh=0.5):\n",
    "    i1 = 0\n",
    "    i2 = 0\n",
    "    res = []\n",
    "    for i1, pred_span in enumerate(pred_spans):\n",
    "        for i2, gold_span in enumerate(gold_spans):\n",
    "            gold_begin = gold_span[0]\n",
    "            gold_end = gold_span[1]\n",
    "            \n",
    "            pred_begin = pred_span[0]\n",
    "            pred_end = pred_span[1]\n",
    "            \n",
    "            len_gold = gold_end - gold_begin\n",
    "            len_pred = pred_end - pred_begin\n",
    "            min_l = min(len_gold, len_pred)\n",
    "            \n",
    "            if thresh == 1:\n",
    "                if pred_span == gold_span:\n",
    "                    res.append((i1, i2))\n",
    "                    \n",
    "            else:\n",
    "\n",
    "                if pred_end > gold_begin and pred_end < gold_end and pred_begin < gold_begin:\n",
    "                    overlap = (pred_end - gold_begin) / min_l\n",
    "                    if overlap >= thresh:\n",
    "                        res.append((i1, i2))\n",
    "                elif gold_end > pred_begin and gold_end < pred_end and pred_begin > gold_begin:\n",
    "                    overlap = (gold_end - pred_begin) / min_l\n",
    "                    if overlap >= thresh:\n",
    "                        res.append((i1, i2))\n",
    "                elif pred_begin >= gold_begin and pred_end <= gold_end:\n",
    "                    res.append((i1, i2))\n",
    "                elif gold_begin >= pred_begin and gold_end <= pred_end:\n",
    "                    res.append((i1, i2))\n",
    "    \n",
    "    # If same mention is counted twice, only add it once\n",
    "    i1_cov = set()\n",
    "    i2_cov = set()\n",
    "    final_res = []\n",
    "    for i1, i2 in res:\n",
    "        if i1 not in i1_cov and i2 not in i2_cov:\n",
    "            i1_cov.add(i1)\n",
    "            i2_cov.add(i2)\n",
    "            final_res.append((i1, i2))\n",
    "     \n",
    "    return final_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_full(results, dataset='conll-dev', verbose=False, mention_thresh=0.5, tagme_thresh=0.1):\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "    num_detected = 0\n",
    "    match_idxss = []\n",
    "    not_covered_idxss = []\n",
    "\n",
    "    for k, preds in results.items():\n",
    "        if k not in gold[dataset]:\n",
    "            if verbose:\n",
    "                print('not in gold', k)\n",
    "            continue\n",
    "        if isinstance(preds, dict):\n",
    "            pred_spans = preds['spans']\n",
    "            pred_titles = preds['ents']\n",
    "        else:\n",
    "            pred_spans = [(ann.begin, ann.end) for ann in preds.get_annotations(tagme_thresh)]\n",
    "            pred_titles = [tagme.normalize_title(ann.entity_title) for ann in preds.get_annotations(tagme_thresh)]\n",
    "        num_detected += len(pred_spans)\n",
    "            \n",
    "        correct_spans = gold[dataset][k]['spans']\n",
    "        overlap = common_idx(pred_spans, correct_spans, thresh=mention_thresh)\n",
    "        if verbose:\n",
    "            print(f'Correct: {correct_spans}')\n",
    "            print(f'Predicted: {pred_spans}')\n",
    "            print(f'Overlap: {overlap}\\n\\n')\n",
    "\n",
    "        match = [(gold[dataset][k]['ents'][correct_idx], pred_titles[pred_idx]) for pred_idx, correct_idx in overlap]\n",
    "        match = [(rd.get(t[0], t[0]), rd.get(t[1], t[1])) for t in match]\n",
    "        \n",
    "        match_idxs = [correct_idx for pred_idx, correct_idx in overlap]\n",
    "        match_idxss.append(match_idxs)\n",
    "        not_covered_idxs = [idx for idx, _ in enumerate(gold[dataset][k]['ents']) if idx not in match_idxs]\n",
    "        not_covered_idxss.append(not_covered_idxs)\n",
    "        \n",
    "        correct = 0\n",
    "        for m in match:\n",
    "            total += 1\n",
    "            if m[0] == m[1]:\n",
    "                correct += 1\n",
    "                total_correct += 1\n",
    "        local_acc = correct / len(match) if len(match) else 0\n",
    "        \n",
    "        if verbose:\n",
    "            if local_acc < 0.2:\n",
    "                print(match)\n",
    "    \n",
    "    return num_detected, total_correct, total, match_idxss, not_covered_idxss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_mention(results, dataset='conll-dev'):\n",
    "    num_correct = 0\n",
    "    total = 0\n",
    "    num_no_link = 0\n",
    "    no_links = []\n",
    "    correct_triples = []\n",
    "    incorrect_triples = []\n",
    "\n",
    "    for k, v in mention_results.items():\n",
    "        if k not in gold[DATASET]:\n",
    "            print(k, v)\n",
    "            continue\n",
    "        gold_ents = gold[DATASET][k]['ents']\n",
    "        pred_ents = v['ents']\n",
    "        mentions = gold[DATASET][k]['mentions']\n",
    "        for i, (mention, gold_ent, pred_ent) in enumerate(zip(mentions, gold_ents, pred_ents)):\n",
    "\n",
    "            gold_ent = rd.get(gold_ent, gold_ent)\n",
    "            pred_ent = rd.get(pred_ent, pred_ent)\n",
    "            triple = mention, pred_ent, gold_ent\n",
    "            total += 1\n",
    "            if pred_ent == 'NO LINK FOUND':\n",
    "                num_no_link += 1\n",
    "                no_links.append(gold_ent)\n",
    "            if gold_ent == pred_ent:\n",
    "                correct_triples.append(triple)\n",
    "                num_correct += 1\n",
    "            else:\n",
    "                incorrect_triples.append(triple)\n",
    "                pass\n",
    "            \n",
    "    return num_correct, total, num_no_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eval full pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "our_results, our_times = get_full_results(2000, dataset=DATASET, max_cands=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len</th>\n",
       "      <th>time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3380.150000</td>\n",
       "      <td>1.717229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1426.553715</td>\n",
       "      <td>0.775217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>941.000000</td>\n",
       "      <td>0.664579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2220.500000</td>\n",
       "      <td>0.886270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3714.000000</td>\n",
       "      <td>1.939450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4500.000000</td>\n",
       "      <td>2.373915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5821.000000</td>\n",
       "      <td>3.049635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               len   time (s)\n",
       "count    20.000000  20.000000\n",
       "mean   3380.150000   1.717229\n",
       "std    1426.553715   0.775217\n",
       "min     941.000000   0.664579\n",
       "25%    2220.500000   0.886270\n",
       "50%    3714.000000   1.939450\n",
       "75%    4500.000000   2.373915\n",
       "max    5821.000000   3.049635"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(our_times)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Det Thresh: 0.1, Detection: 793, Num mentions: 656, Match: 591, Correct: 463, P: 0.584, R: 0.706, f: 0.639\n",
      "Det Thresh: 0.5, Detection: 793, Num mentions: 656, Match: 591, Correct: 463, P: 0.584, R: 0.706, f: 0.639\n",
      "Det Thresh: 0.8, Detection: 793, Num mentions: 656, Match: 591, Correct: 463, P: 0.584, R: 0.706, f: 0.639\n",
      "Det Thresh: 0.99, Detection: 793, Num mentions: 656, Match: 590, Correct: 463, P: 0.584, R: 0.706, f: 0.639\n",
      "Det Thresh: 1.0, Detection: 793, Num mentions: 656, Match: 461, Correct: 394, P: 0.497, R: 0.601, f: 0.544\n"
     ]
    }
   ],
   "source": [
    "for mention_thresh in [0.1, 0.5, 0.8, 0.99, 1]:\n",
    "    num_detected, our_correct, our_total, match, not_covered = eval_full(our_results, \n",
    "                                                           dataset=DATASET, \n",
    "                                                           mention_thresh=mention_thresh,\n",
    "                                                           verbose=False)\n",
    "    num_mentions = 0\n",
    "    for k, v in gold[DATASET].items():\n",
    "        num_mentions += len(v['mentions'])\n",
    "    p = our_correct / num_detected\n",
    "    r = our_correct / num_mentions\n",
    "    f = 2 * p * r / (p + r)\n",
    "    print('Det Thresh: {}, Detection: {}, Num mentions: {}, Match: {}, Correct: {}, P: {:.3f}, R: {:.3f}, f: {:.3f}'.format(float(mention_thresh),\n",
    "                                                                                                                            num_detected,\n",
    "                                                                                                                            num_mentions,\n",
    "                                                                                                                            our_total,\n",
    "                                                                                                                            our_correct,\n",
    "                                                                                                                            p,\n",
    "                                                                                                                            r,\n",
    "                                                                                                                            f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8546637744034707"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "394 / 461"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eval only linking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mention_results = get_mention_results(20000, dataset=DATASET, max_cands=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4253 4825 84 0.8814507772020725\n"
     ]
    }
   ],
   "source": [
    "num_correct, total, num_no_link = eval_mention(mention_results, dataset=DATASET)\n",
    "print(num_correct, total, num_no_link, num_correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "572"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4825 - 4253"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tagme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tagme_results(num_text, dataset='conll-dev'):\n",
    "    results = {}\n",
    "    times = []\n",
    "    for i, (doc_id, text) in enumerate(list(id2c[dataset].items())[:num_text]):\n",
    "        text =  id2c[dataset][doc_id] \n",
    "        tic = datetime.now()\n",
    "        results[doc_id] = tagme.annotate(text)\n",
    "        toc = datetime.now()\n",
    "        times.append({'len': len(text), 'time (s)': (toc - tic).total_seconds()})\n",
    "    if i % 20 == 0:\n",
    "        print(i, i / num_text)\n",
    "\n",
    "    return results, times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagme_results, tagme_times = get_tagme_results(len(id2c[DATASET]), dataset=DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len</th>\n",
       "      <th>time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>217.000000</td>\n",
       "      <td>217.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1295.382488</td>\n",
       "      <td>1.678940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1043.489772</td>\n",
       "      <td>3.296380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>165.000000</td>\n",
       "      <td>0.257416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>545.000000</td>\n",
       "      <td>0.527650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>990.000000</td>\n",
       "      <td>0.922129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1728.000000</td>\n",
       "      <td>1.786551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6198.000000</td>\n",
       "      <td>43.165836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               len    time (s)\n",
       "count   217.000000  217.000000\n",
       "mean   1295.382488    1.678940\n",
       "std    1043.489772    3.296380\n",
       "min     165.000000    0.257416\n",
       "25%     545.000000    0.527650\n",
       "50%     990.000000    0.922129\n",
       "75%    1728.000000    1.786551\n",
       "max    6198.000000   43.165836"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(tagme_times)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag Thresh: 0.1, Mention Thresh: 0.1, Detection: 11118, Num mentions: 4825, Match: 4433, Correct: 3090\n",
      "Tag Thresh: 0.1, Mention Thresh: 0.5, Detection: 11118, Num mentions: 4825, Match: 4433, Correct: 3090\n",
      "Tag Thresh: 0.1, Mention Thresh: 0.8, Detection: 11118, Num mentions: 4825, Match: 4433, Correct: 3092\n",
      "Tag Thresh: 0.1, Mention Thresh: 1, Detection: 11118, Num mentions: 4825, Match: 4206, Correct: 3066\n",
      "Tag Thresh: 0.15, Mention Thresh: 0.1, Detection: 8562, Num mentions: 4825, Match: 4154, Correct: 2960\n",
      "Tag Thresh: 0.15, Mention Thresh: 0.5, Detection: 8562, Num mentions: 4825, Match: 4154, Correct: 2960\n",
      "Tag Thresh: 0.15, Mention Thresh: 0.8, Detection: 8562, Num mentions: 4825, Match: 4154, Correct: 2961\n",
      "Tag Thresh: 0.15, Mention Thresh: 1, Detection: 8562, Num mentions: 4825, Match: 3944, Correct: 2932\n",
      "Tag Thresh: 0.2, Mention Thresh: 0.1, Detection: 6766, Num mentions: 4825, Match: 3860, Correct: 2818\n",
      "Tag Thresh: 0.2, Mention Thresh: 0.5, Detection: 6766, Num mentions: 4825, Match: 3860, Correct: 2818\n",
      "Tag Thresh: 0.2, Mention Thresh: 0.8, Detection: 6766, Num mentions: 4825, Match: 3860, Correct: 2819\n",
      "Tag Thresh: 0.2, Mention Thresh: 1, Detection: 6766, Num mentions: 4825, Match: 3667, Correct: 2791\n",
      "Tag Thresh: 0.3, Mention Thresh: 0.1, Detection: 4568, Num mentions: 4825, Match: 3171, Correct: 2426\n",
      "Tag Thresh: 0.3, Mention Thresh: 0.5, Detection: 4568, Num mentions: 4825, Match: 3171, Correct: 2426\n",
      "Tag Thresh: 0.3, Mention Thresh: 0.8, Detection: 4568, Num mentions: 4825, Match: 3170, Correct: 2427\n",
      "Tag Thresh: 0.3, Mention Thresh: 1, Detection: 4568, Num mentions: 4825, Match: 3019, Correct: 2399\n",
      "Tag Thresh: 0.5, Mention Thresh: 0.1, Detection: 1501, Num mentions: 4825, Match: 1224, Correct: 1043\n",
      "Tag Thresh: 0.5, Mention Thresh: 0.5, Detection: 1501, Num mentions: 4825, Match: 1224, Correct: 1043\n",
      "Tag Thresh: 0.5, Mention Thresh: 0.8, Detection: 1501, Num mentions: 4825, Match: 1223, Correct: 1043\n",
      "Tag Thresh: 0.5, Mention Thresh: 1, Detection: 1501, Num mentions: 4825, Match: 1174, Correct: 1032\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for tag_thresh in [0.1, 0.15, 0.2, 0.3, 0.5]:\n",
    "    for mention_thresh in [0.1, 0.5, 0.8, 1]:\n",
    "        num_detected, tagme_correct, tagme_total, _, _ = eval_full(tagme_results,\n",
    "                                                                  dataset=DATASET, \n",
    "                                                                  mention_thresh=mention_thresh,\n",
    "                                                                  tagme_thresh=tag_thresh)\n",
    "        num_mentions = 0\n",
    "        for k, v in gold[DATASET].items():\n",
    "            num_mentions += len(v['mentions'])\n",
    "        res.append({'Tag Thesh': tag_thresh,\n",
    "                    'Mention Thresh': mention_thresh,\n",
    "                    'Detection': num_detected,\n",
    "                    'Num mentions': num_mentions,\n",
    "                    'Match': tagme_total,\n",
    "                    'Correct': tagme_correct})\n",
    "        print('Tag Thresh: {}, Mention Thresh: {}, Detection: {}, Num mentions: {}, Match: {}, Correct: {}'.format(tag_thresh,\n",
    "                                                                                                               mention_thresh,\n",
    "                                                                                                               num_detected, \n",
    "                                                                                                               num_mentions,\n",
    "                                                                                                               tagme_total,\n",
    "                                                                                                               tagme_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tagme = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tagme.to_csv('tagme.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mannheim-nel)",
   "language": "python",
   "name": "mannheim-nel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
