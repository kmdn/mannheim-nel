{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-837f162fc4c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'..'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtagme\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import sys\n",
    "from os.path import join\n",
    "import pickle\n",
    "sys.path.append('..')\n",
    "from utils import *\n",
    "from collections import defaultdict\n",
    "import tagme\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import Levenshtein\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/rohitalyosha/Student_Job/mannheim-nel/data'\n",
    "datasets = ['conll-train', 'conll-dev', 'msnbc', 'ace2004']\n",
    "tagme.GCUBE_TOKEN = \"88c693df-a43f-4086-b3bc-0b555bfbc9bb-843339462\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd = json_load(join(data_path, 'dicts/redirects.json'))\n",
    "ent2id = json_load('/home/rohitalyosha/Student_Job/mannheim-nel/data/dicts/ent_dict.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2c = {}\n",
    "id2c_conll = pickle_load(join(data_path, 'Conll', 'conll_raw_text.pickle'))\n",
    "id2c['conll-train'] = id2c_conll['train']\n",
    "id2c['conll-dev'] = id2c_conll['dev']\n",
    "examples = {}\n",
    "\n",
    "for d_name in datasets[2:]:\n",
    "    id2c[d_name], examples[d_name] = pickle_load(join(data_path, 'datasets', f'raw_{d_name}.pickle'))\n",
    "\n",
    "for d_name in datasets[:2]:\n",
    "    _, examples[d_name] = pickle_load(join(data_path, 'Conll', f\"conll-{d_name.split('-')[-1]}.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = {dataset : {} for dataset in datasets}\n",
    "for dataset, exs in examples.items():\n",
    "    for ex in exs:\n",
    "        c_id, (mention, ent_str, span, _) = ex\n",
    "        if c_id not in gold[dataset]:\n",
    "            gold[dataset][c_id] = {'mentions': [],\n",
    "                          'ents': [],\n",
    "                          'spans': []}\n",
    "        gold[dataset][c_id]['mentions'].append(mention)\n",
    "        gold[dataset][c_id]['ents'].append(ent_str)\n",
    "        gold[dataset][c_id]['spans'].append(span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "barack_text = \"\"\"Barack Hussein Obama II (/bəˈrɑːk huːˈseɪn oʊˈbɑːmə/ (About this sound listen);[1] born August 4, 1961) is an American politician who served as the 44th President of the United States from January 20, 2009, to January 20, 2017. A member of the Democratic Party, he was the first African American to be elected to the presidency and previously served as a United States Senator from Illinois (2005–2008).\n",
    "Obama was born in 1961 in Honolulu, Hawaii, two years after the territory was admitted to the Union as the 50th state. Raised largely in Hawaii, he also lived for a year of his childhood in the State of Washington and four years in Indonesia. After graduating from Columbia University in 1983, he worked as a community organizer in Chicago. In 1988, he enrolled in Harvard Law School, where he was the first black president of the Harvard Law Review. After graduating, he became a civil rights attorney and a professor, teaching constitutional law at the University of Chicago Law School from 1992 to 2004. He represented the 13th district for three terms in the Illinois Senate from 1997 to 2004, when he ran for the U.S. Senate. He received national attention in 2004 with his March primary win, his well-received July Democratic National Convention keynote address, and his landslide November election to the Senate. In 2008, he was nominated for president a year after his campaign began and after a close primary campaign against Hillary Clinton. He was elected over Republican John McCain and was inaugurated on January 20, 2009. Nine months later, he was named the 2009 Nobel Peace Prize laureate, accepting the award with the caveat that he felt there were others \"far more deserving of this honor than I\".\n",
    "During his first two years in office, Obama signed many landmark bills into law. The main reforms were the Patient Protection and Affordable Care Act (often referred to as \"Obamacare\", shortened as the \"Affordable Care Act\"), the Dodd–Frank Wall Street Reform and Consumer Protection Act, and the Don't Ask, Don't Tell Repeal Act of 2010. The American Recovery and Reinvestment Act of 2009 and Tax Relief, Unemployment Insurance Reauthorization, and Job Creation Act of 2010 served as economic stimulus amidst the Great Recession. After a lengthy debate over the national debt limit, he signed the Budget Control and the American Taxpayer Relief Acts. In foreign policy, he increased U.S. troop levels in Afghanistan, reduced nuclear weapons with the United States–Russia New START treaty, and ended military involvement in the Iraq War. He ordered military involvement in Libya in opposition to Muammar Gaddafi; Gaddafi was killed by NATO-assisted forces, and he also ordered the military operation that resulted in the deaths of Osama bin Laden and suspected Yemeni Al-Qaeda operative Anwar al-Awlaki.\n",
    "\"\"\"\n",
    "barack_mentions = ['President', 'United States', 'African American', 'Democratic Party']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_full(text):\n",
    "    data_json = json.dumps({'text': text})\n",
    "    response_json = requests.post(\"http://127.0.0.1:5000/full\", data=data_json).json()\n",
    "    ents = response_json['entities']\n",
    "    mentions = response_json['mentions']\n",
    "    spans = response_json['spans']\n",
    "    \n",
    "    return ents, mentions, spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_mention(text, user_mentions, user_spans):\n",
    "    data_json = json.dumps({'text': text, 'mentions': user_mentions, 'spans': user_spans})\n",
    "    response_json = requests.post(\"http://127.0.0.1:5000/link\", data=data_json).json()\n",
    "    ents = response_json['entities']\n",
    "    mentions = response_json['mentions']\n",
    "    \n",
    "    return ents, mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_results(num_text, dataset='dev'):\n",
    "    results = {}\n",
    "    times = []\n",
    "    for doc_id, text in list(id2c[dataset].items())[:num_text]:\n",
    "        results[doc_id] = {}\n",
    "\n",
    "        tic = datetime.now()\n",
    "        ents, mentions, spans = get_response_full(text)\n",
    "        toc = datetime.now()\n",
    "        times.append({'len': len(text), 'time (s)': (toc - tic).total_seconds()})\n",
    "        results[doc_id]['mentions'] = mentions\n",
    "        results[doc_id]['ents'] = ents\n",
    "        results[doc_id]['spans'] = [tuple(span) for span in spans]\n",
    "    \n",
    "    return results, times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mention_results(num_text, dataset='conll-dev'):\n",
    "    results = {}\n",
    "    times = []\n",
    "    for doc_id, text in list(id2c[dataset].items())[:num_text]:\n",
    "        if doc_id not in gold[dataset]:\n",
    "            continue\n",
    "        results[doc_id] = {}\n",
    "        user_mentions = gold[dataset][doc_id]['mentions']\n",
    "        user_spans = gold[dataset][doc_id]['spans']\n",
    "        try:\n",
    "            ents, mentions = get_response_mention(text, user_mentions, user_spans)\n",
    "        except Exception as e:\n",
    "            print(Text, user_mentions)\n",
    "        results[doc_id]['mentions'] = mentions\n",
    "        results[doc_id]['ents'] = ents\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_idx_strict(l1, l2):\n",
    "    i1 = 0\n",
    "    i2 = 0\n",
    "    res = []\n",
    "    while i1 < len(l1) and i2 < len(l2):\n",
    "        if l1[i1] == l2[i2]:\n",
    "            res.append((i1, i2))\n",
    "            i1 += 1\n",
    "            i2 += 1\n",
    "        elif l2[i2][0] >= l1[i1][0]:\n",
    "            i1 += 1\n",
    "        elif l2[i2][0] < l1[i1][0]:\n",
    "            i2 += 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_idx_lenient(pred_spans, gold_spans, thresh=0.5):\n",
    "    if thresh == 1:\n",
    "        return common_idx_strict(pred_spans, gold_spans)\n",
    "    i1 = 0\n",
    "    i2 = 0\n",
    "    res = []\n",
    "    for i1, pred_span in enumerate(pred_spans):\n",
    "        for i2, gold_span in enumerate(gold_spans):\n",
    "            gold_begin = gold_span[0]\n",
    "            gold_end = gold_span[1]\n",
    "            len_gold = gold_end - gold_begin\n",
    "\n",
    "            pred_begin = pred_spans[i1][0]\n",
    "            pred_end = pred_spans[i1][1]\n",
    "\n",
    "            if pred_span == gold_span:\n",
    "                res.append((i1, i2))\n",
    "            elif pred_end >= gold_begin and pred_end <= gold_end:\n",
    "                overlap = (pred_end - gold_begin) / len_gold\n",
    "                if overlap >= thresh:\n",
    "                    res.append((i1, i2))\n",
    "            elif gold_end >= pred_begin and gold_end <= pred_end:\n",
    "                overlap = (gold_end - pred_begin) / len_gold\n",
    "                if overlap >= thresh:\n",
    "                    res.append((i1, i2))\n",
    "                    \n",
    "    i1_cov = set()\n",
    "    i2_cov = set()\n",
    "    final_res = []\n",
    "    for i1, i2 in res:\n",
    "        if i1 not in i1_cov and i2 not in i2_cov:\n",
    "            i1_cov.add(i1)\n",
    "            i2_cov.add(i2)\n",
    "            final_res.append((i1, i2))\n",
    "\n",
    "        \n",
    "    return final_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_strict_mention(results, dataset='dev', verbose=False):\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "    num_no_link = 0\n",
    "    no_links = []\n",
    "\n",
    "    for k, preds in results.items():\n",
    "        if k not in gold[dataset]:\n",
    "            print('not in gold', k)\n",
    "            continue\n",
    "        if isinstance(preds, dict):\n",
    "            pred_spans = preds['spans']\n",
    "            pred_titles = preds['ents']\n",
    "        else:\n",
    "            pred_spans = [(ann.begin, ann.end) for ann in preds.get_annotations(0)]\n",
    "            pred_titles = [tagme.normalize_title(ann.entity_title) for ann in preds.get_annotations(0)]\n",
    "            \n",
    "        correct_spans = gold[dataset][k]['spans']\n",
    "        overlap = common_idx_strict(pred_spans, correct_spans)\n",
    "        match = [(gold[dataset][k]['ents'][correct_idx], pred_titles[pred_idx]) for pred_idx, correct_idx in overlap]\n",
    "        match = [(rd.get(t[0], t[0]), rd.get(t[1], t[1])) for t in match]\n",
    "        correct = 0\n",
    "        for m in match:\n",
    "            total += 1\n",
    "            if m[0] == m[1]:\n",
    "                correct += 1\n",
    "                total_correct += 1\n",
    "        local_acc = correct / len(match) if len(match) else 0\n",
    "        \n",
    "        if verbose:\n",
    "            if local_acc < 0.2:\n",
    "                print(match)\n",
    "    \n",
    "    return total_correct, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_lenient_mention(results, dataset='dev', verbose=False, mention_thresh=0.5, tagme_thresh=0.1):\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "    num_detected = 0\n",
    "    match_idxss = []\n",
    "    not_covered_idxss = []\n",
    "\n",
    "    for k, preds in results.items():\n",
    "        if k not in gold[dataset]:\n",
    "            #print('not in gold', k)\n",
    "            continue\n",
    "        if isinstance(preds, dict):\n",
    "            pred_spans = preds['spans']\n",
    "            pred_titles = preds['ents']\n",
    "        else:\n",
    "            pred_spans = [(ann.begin, ann.end) for ann in preds.get_annotations(tagme_thresh)]\n",
    "            pred_titles = [tagme.normalize_title(ann.entity_title) for ann in preds.get_annotations(tagme_thresh)]\n",
    "        num_detected += len(pred_spans)\n",
    "            \n",
    "        correct_spans = gold[dataset][k]['spans']\n",
    "        overlap = common_idx_lenient(pred_spans, correct_spans, thresh=mention_thresh)\n",
    "\n",
    "        match = [(gold[dataset][k]['ents'][correct_idx], pred_titles[pred_idx]) for pred_idx, correct_idx in overlap]\n",
    "        match = [(rd.get(t[0], t[0]), rd.get(t[1], t[1])) for t in match]\n",
    "        \n",
    "        match_idxs = [correct_idx for pred_idx, correct_idx in overlap]\n",
    "        match_idxss.append(match_idxs)\n",
    "        not_covered_idxs = [idx for idx, _ in enumerate(gold[dataset][k]['ents']) if idx not in match_idxs]\n",
    "        not_covered_idxss.append(not_covered_idxs)\n",
    "        \n",
    "        correct = 0\n",
    "        for m in match:\n",
    "            total += 1\n",
    "            if m[0] == m[1]:\n",
    "                correct += 1\n",
    "                total_correct += 1\n",
    "        local_acc = correct / len(match) if len(match) else 0\n",
    "        \n",
    "        if verbose:\n",
    "            if local_acc < 0.2:\n",
    "                print(match)\n",
    "    \n",
    "    return num_detected, total_correct, total, match_idxss, not_covered_idxss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eval full pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'conll-dev'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_results, our_times = get_full_results(2000, dataset=DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Det Thresh: 0.1\n",
      "Detection: 4957, Num mentions: 4825, Match: 4009, Correct: 3301\n",
      "Det Thresh: 0.5\n",
      "Detection: 4957, Num mentions: 4825, Match: 3983, Correct: 3292\n",
      "Det Thresh: 0.8\n",
      "Detection: 4957, Num mentions: 4825, Match: 3959, Correct: 3276\n",
      "Det Thresh: 1\n",
      "Detection: 4957, Num mentions: 4825, Match: 3499, Correct: 3031\n"
     ]
    }
   ],
   "source": [
    "for det_thresh in [0.1, 0.5, 0.8, 1]:\n",
    "    num_detected, our_correct, our_total, match_idxss, not_covered_idxss = eval_lenient_mention(our_results, \n",
    "                                                                                              dataset=DATASET, \n",
    "                                                                                              thresh=det_thresh)\n",
    "    num_mentions = 0\n",
    "    for k, v in gold[DATASET].items():\n",
    "        num_mentions += len(v['mentions'])\n",
    "    print(f'Det Thresh: {det_thresh}' )\n",
    "    print('Detection: {}, Num mentions: {}, Match: {}, Correct: {}'.format(num_detected, num_mentions, our_total, our_correct))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eval only linking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'ace2004'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "mention_results = get_mention_results(500, dataset=DATASET)\n",
    "\n",
    "num_correct = 0\n",
    "total = 0\n",
    "num_no_link = 0\n",
    "no_links = []\n",
    "\n",
    "for k, v in mention_results.items():\n",
    "    if k not in gold[DATASET]:\n",
    "        print(k, v)\n",
    "        continue\n",
    "    gold_ents = gold[DATASET][k]['ents']\n",
    "    pred_ents = v['ents']\n",
    "    gold_mentions = gold[DATASET][k]['mentions']\n",
    "    for i, (gold_ent, pred_ent) in enumerate(zip(gold_ents, pred_ents)):\n",
    "        gold_ent = rd.get(gold_ent, gold_ent)\n",
    "        pred_ent = rd.get(pred_ent, pred_ent)\n",
    "        total += 1\n",
    "        if pred_ent == 'NO LINK FOUND':\n",
    "            num_no_link += 1\n",
    "            no_links.append(gold_ent)\n",
    "        if gold_ent == pred_ent:\n",
    "            num_correct += 1\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219 257 0.8521400778210116\n"
     ]
    }
   ],
   "source": [
    "print(num_correct, total, num_correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tagme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tagme_results(num_text, dataset='conll-dev'):\n",
    "    results = {}\n",
    "    times = []\n",
    "    for i, (doc_id, text) in enumerate(list(id2c[dataset].items())[:num_text]):\n",
    "        text =  id2c[dataset][doc_id] \n",
    "        tic = datetime.now()\n",
    "        results[doc_id] = tagme.annotate(text)\n",
    "        toc = datetime.now()\n",
    "        times.append({'len': len(text), 'time (s)': (toc - tic).total_seconds()})\n",
    "    if i % 20 == 0:\n",
    "        print(i, i / num_text)\n",
    "\n",
    "    return results, times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'msnbc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagme_results, tagme_times = get_tagme_results(len(id2c[DATASET]), dataset=DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag_thresh in [0.1, 0.3, 0.5]:\n",
    "    for det_thresh in [0.1, 0.5, 0.8, 1]:\n",
    "        num_detected, tagme_correct, tagme_total, _, _ = eval_lenient_mention(tagme_results,\n",
    "                                                                        dataset=DATASET, \n",
    "                                                                        mention_thresh=det_thresh,\n",
    "                                                                        tagme_thresh=tag_thresh)\n",
    "        num_mentions = 0\n",
    "        for k, v in gold[DATASET].items():\n",
    "            num_mentions += len(v['mentions'])\n",
    "        print('Tag Thresh: {}, Det Thresh: {}, Detection: {}, Num mentions: {}, Match: {}, Correct: {}'.format(tag_thresh,\n",
    "                                                                                                               det_thresh,\n",
    "                                                                                                               num_detected, \n",
    "                                                                                                               num_mentions,\n",
    "                                                                                                               tagme_total,\n",
    "                                                                                                               tagme_correct))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mannheim-nel)",
   "language": "python",
   "name": "mannheim-nel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
